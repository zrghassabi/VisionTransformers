# VisionTransformers

Implementation from scratch

https://towardsdatascience.com/implementing-visualttransformer-in-pytorch-184f9f16f632

An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (Paper Explained)
https://www.youtube.com/watch?v=TrdevFK_am4&t=1000s

For more info: https://jalammar.github.io/illustrated-transformer/

Einops tutorial : https://einops.rocks/1-einops-basics/


- Data
- Patches Embeddings
    - CLS Token
    - Position Embedding
- Transformer
    - Attention
    - Residuals
    - MLP
    - TransformerEncoder
- Head
- ViT

Just pick your favorite vision model from the hub and start fine-tuning it :)

https://huggingface.co/models?other=vision


Fine-Tune ViT for Image Classification with ðŸ¤— Transformers
https://huggingface.co/blog/fine-tune-vit

Transformers in hugging face 
https://huggingface.co/docs/transformers/v4.19.4/en/model_doc/vit#transformers.ViTFeatureExtractor

How fintune Vision Transformers on costum dataset (CIFAR-10):

performing inference with ViT to illustrate image classification

fine-tuning ViT on CIFAR-10 using HuggingFace's Trainer

fine-tuning ViT on CIFAR-10 using PyTorch Lightning

https://github.com/NielsRogge/Transformers-Tutorials/tree/master/VisionTransformer


